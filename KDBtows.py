import streamlit as st
from langchain.document_loaders import PyPDFLoader
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
from dotenv import load_dotenv
import faiss
import pickle

# í‚¤ í˜¸ì¶œ
load_dotenv()

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ
faiss_index = faiss.read_index("faiss_index/index.faiss")

# ë©”íƒ€ë°ì´í„° ë¡œë“œ
with open("faiss_index/index.pkl", "rb") as f:
    metadata = pickle.load(f)

# Streamlit ì•± ì„¤ì •
st.title("ğŸ” FAISS ê¸°ë°˜ ê¸°ì—…ë³„ TOWS ë¶„ì„")
st.write("FAISS ë°ì´í„°ë² ì´ìŠ¤ì™€ OpenAIì˜ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.")

# FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ í•¨ìˆ˜
def create_or_load_faiss_index(folder_path, faiss_file_path, chunk_size=1000, chunk_overlap=100):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    embeddings = OpenAIEmbeddings()

    if os.path.exists(faiss_file_path):
        vector_store = FAISS(embedding=faiss_index, metadata=metadata)
    else:
        all_docs = []
        for root, _, files in os.walk(folder_path):
            for file_name in files:
                if file_name.endswith(".pdf"):
                    file_path = os.path.join(root, file_name)
                    loader = PyPDFLoader(file_path)
                    documents = loader.load()
                    docs = text_splitter.split_documents(documents)
                    all_docs.extend(docs)

        vector_store = FAISS.from_documents(all_docs, embeddings)
        vector_store.save_local(faiss_file_path)
    return vector_store


# TOWS ë¶„ì„ ìƒì„± í•¨ìˆ˜
def generate_tows_analysis(query, vector_store):
    """FAISS ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ TOWS ë¶„ì„ ìƒì„±"""
    try:
        # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        docs = vector_store.similarity_search(query, k=3)
        context = "\n".join([doc.page_content for doc in docs])

        # OpenAI LLM í˜¸ì¶œ
        prompt = f"""
        ë¬¸ë§¥:
        {context}

        ìœ„ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ TOWS ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        {query}

        í˜•ì‹:
        ìœ„í˜‘ (Threats):
        - í•­ëª© 1
        - í•­ëª© 2

        ê¸°íšŒ (Opportunities):
        - í•­ëª© 1
        - í•­ëª© 2

        ì•½ì  (Weaknesses):
        - í•­ëª© 1
        - í•­ëª© 2

        ê°•ì  (Strengths):
        - í•­ëª© 1
        - í•­ëª© 2
        """

        llm = ChatOpenAI(model="gpt-4o", temperature=0.7)
        response = llm.predict(prompt)
        return response.strip()
    except Exception as e:
        return f"ì—ëŸ¬ ë°œìƒ: {str(e)}"



# Streamlit ì•±
st.title("ğŸ” ê¸°ì—…ë³„ TOWS ë¶„ì„")
st.write("OpenAIì˜ GPTë¥¼ ì‚¬ìš©í•˜ì—¬ TOWS ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥
company_name = st.text_input("ë¶„ì„ ëŒ€ìƒ íšŒì‚¬ëª…ì„ ì…ë ¥í•˜ì„¸ìš”:", "KDBì‚°ì—…ì€í–‰")
if st.button("ğŸ”„TOWS ë¶„ì„ ìƒì„±"):
    # TOWS ë¶„ì„ ìƒì„±
    analysis = generate_tows_analysis(company_name)
    if "ì—ëŸ¬ ë°œìƒ" not in analysis:
        # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        st.subheader("âœ”ï¸TOWS ë¶„ì„ ê²°ê³¼")
        st.write(f"\n{analysis}\n")

    else:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {analysis}")
