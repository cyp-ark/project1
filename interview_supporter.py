import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate

# ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ì™€ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
questions = {
    "ê¸ˆìœµ ë° ê²½ì œ": [
        "ESG ê¸ˆìœµì˜ í™œì„±í™” ë°©ì•ˆ",
        "ì‚°ì—…êµ¬ì¡° ê³ ë„í™”ë¥¼ ìœ„í•œ íˆ¬ìì „ëµ",
        "í¬ìŠ¤íŠ¸ ì½”ë¡œë‚˜ ì‹œëŒ€ì˜ ê¸°ì—…êµ¬ì¡°ì¡°ì • ë°©ì•ˆ",
        "ì¤‘ì†Œê¸°ì—… ê¸ˆìœµì§€ì› í™•ëŒ€ ì „ëµ",
        "ë°˜ë„ì²´ ì‚°ì—… ê²½ìŸë ¥ ë¶„ì„ê³¼ ê¸ˆìœµ ì§€ì› ë°©ì•ˆ",
        "ê¸°ì—… ì‹ ìš©í‰ê°€ ëª¨ë¸ ê°œì„  ë°©ì•ˆ",
        "ì‹ ì¬ìƒì—ë„ˆì§€ ì‚°ì—… íˆ¬ìì „ëµ",
        "ìµœê·¼ ê¸€ë¡œë²Œ ê¸ˆìœµì‹œì¥ ì´ìŠˆëŠ”?",
        "ì‚°ì—…ì€í–‰ì˜ ì •ì±…ê¸ˆìœµ ì—­í• ì€?",
        "ë””ì§€í„¸ ê¸ˆìœµì˜ ë°œì „ ë°©í–¥",
    ],
    "ê¸°ì—… ë° ì •ì±…": [
        "êµ¬ì¡°ì¡°ì • ëŒ€ìƒ ê¸°ì—… ì‹¤ì‚¬ ë°©ì•ˆ",
        "ê¸°ì—…ê°€ì¹˜ í‰ê°€ ë°©ë²•ë¡  ì„¤ëª…",
        "ì°½ì—…ì´ë¼ëŠ” íŠ¹ì´í•œ ì´ë ¥ì„ ê°–ê³  ìˆëŠ”ë°, ë³¸ì¸ì´ ë‹´ë‹¹í–ˆë˜ í¬ì§€ì…˜ì€ ë¬´ì—‡ì¸ì§€?",
        "ë²¤ì²˜ê¸°ì—… ì§€ì›ì— ê´€ì‹¬ì´ ìˆë‹¤ê³  í–ˆëŠ”ë°, ì •ì±…ê¸ˆìœµì„ í†µí•´ íˆ¬ì ë° ì§€ì›ì´ ë°˜ë“œì‹œ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë¶„ì•¼ëŠ” ì–´ë””ì¸ê°€?",
        "ITë¶„ì•¼ë“  3ì°¨ ì„œë¹„ìŠ¤ ë¶„ì•¼ë“  ì¼ë‹¨ ìˆ˜ìµì´ ë°œìƒí•˜ëŠ” ë¶„ì•¼ë¶€í„° ì§€ì›í•´ì•¼ í•œë‹¤ëŠ” ì˜ê²¬ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€?",
        "ì‚°ì—…ì€í–‰ ëª¨ë°”ì¼ ë±…í‚¹ê³¼ ë‹¤ë¥¸ ì€í–‰ì˜ ëª¨ë°”ì¼ ë±…í‚¹ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "í•œêµ­ì‚°ì—…ì€í–‰ì— ê´€ë ¨í•œ ìµœê·¼ ì´ìŠˆë¥¼ ë§í•´ë³´ì„¸ìš”",
        "ì‚°ì—…ì€í–‰ë‹´ë‹¹ìë¼ë©´ ì–´ë–¤ ê¸°ì—…ì˜ M&Aë¥¼ ì£¼ì„ í•˜ê² ëŠ”ê°€?",
        "ê¸°ì—…ì˜ ì¡´ì¬ ì´ìœ ëŠ” ë­ë¼ê³  ìƒê°í•©ë‹ˆê¹Œ?",
    ],
    "ê°œì¸ ë° ê²½í—˜": [
        "30ì´ˆ ìê¸°ì†Œê°œ",
        "ê³µëª¨ì „ í™œë™ì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í™œë™ì¸ì§€? ê°ˆë“± ê²½í—˜ì´ ìˆì—ˆëŠ”ì§€?",
        "ê¸°ì¡´ ë¶ˆí¸ì‚¬í•­ì„ ì´ë ‡ê²Œ ë°”ê¿”ë´¤ë‹¤!í•˜ëŠ” ê²½í—˜?",
        "ì¡°ì§ì— ë“¤ì–´ì™”ì„ ë•Œ ì–´ë–¤ ë¶„ìœ„ê¸°ë¥¼ ì œì¼ í˜ë“¤ì–´í•˜ëŠ”ê°€? ê·¸ ì–´ë ¤ì›€ì„ ì–´ë–»ê²Œ í•´ê²°í•´ ë‚˜ê°ˆ ê²ƒì¸ê°€?",
        "ë‚˜ì˜ ê°•ì  í•œê°€ì§€ í˜¹ì€ íƒ€ì¸ìœ¼ë¡œë¶€í„° ë“¤ì—ˆë˜ ë§",
        "ìì‹ ì´ ë¦¬ë”ë¼ê³  ìƒê°í•©ë‹ˆê¹Œ, íŒ”ë¡œì›Œë¼ê³  ìƒê°í•©ë‹ˆê¹Œ?",
        "ì‘ë…„ì—ë„ ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í–ˆëŠ”ë°, ë©´ì ‘ì—ì„œ ì™œ íƒˆë½í•œ ê²ƒ ê°™ë‚˜ìš”?",
        "ì‚°ì—…ì€í–‰ê³¼ ê¸°íƒ€ ê³µê¸°ì—…ì˜ ì°¨ì´ì ì€?",
        "ìì‹ ì˜ ê°€ì¥ í° ì¥ì ì´ ë¬´ì—‡ì¸ê°€?",
    ],
    "ì‚¬íšŒ ë° ê¸°íƒ€": [
        "ì†Œë“ ë¶ˆí‰ë“±",
        "ì´ˆë“±í•™êµì—ì„œ ì¸ì„±êµìœ¡ì„ ì‹œí‚¤ëŠ” ê²ƒì— ëŒ€í•´ ì°¬ë°˜ í† ë¡ ì„ í•˜ë¼",
        "ë¯¸êµ­ ì •ì¹˜ ìº í˜ì¸ì´ í•œêµ­ê³¼ ì–´ë–¤ ì ì—ì„œ ë‹¤ë¥´ë‹¤ê³  ìƒê°í•˜ëŠ”ê°€?",
        "ë³¸ì¸ì´ ìƒê°í•˜ëŠ” ì„±ê³µì´ë€ ë¬´ì—‡ì¸ê°€?",
        "ì •ì˜ë€ ë¬´ì—‡ì´ë¼ ìƒê°í•˜ëŠ”ê°€?",
        "êµ­ë¯¼ì—°ê¸ˆì œë„ì— ê´€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê°€?",
        "ê·€í™”í•œ ì„ ìˆ˜ê°€ ì˜¬ë¦¼í”½ ì¶œì „ì„ í†µí•´ ê¸ˆë©”ë‹¬ íšë“í•˜ëŠ” ê²ƒì— ëŒ€í•œ ì˜ê²¬",
        "ì‚¬ê´€í•™êµ ê·œì œì— ê´€í•œ ë³¸ì¸ì˜ ìƒê°",
        "í•˜ìš°ìŠ¤í‘¸ì–´ ì§€ì›ì— ëŒ€í•œ ì°¬ë°˜",
    ],
}

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
def show():
    # LangChain OpenAI ëª¨ë¸ ì„¤ì •
    llm = ChatOpenAI(
        model = "gpt-4o",
        temperature=0.5,
        )

    # ë‹µë³€ ìºì‹± í•¨ìˆ˜
    @st.cache_data
    def get_answer(question: str) -> str:
        """Generate and cache answers for the given question."""
        prompt = PromptTemplate(
            input_variables=["question"],
            template="You are an expert in interviews. Provide a concise yet insightful answer to the following question in Korean: {question}",
        ).format(question=question)
        return llm.predict(prompt)

    # Streamlit ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.subheader("ğŸ’¼ì‚°ì—…ì€í–‰ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸")
    selected_category = st.selectbox("ë©´ì ‘ ì§ˆë¬¸ì„ ì„ íƒí•˜ì‹œë©´ AIê°€ ë‹µë³€ì„ ì œê³µí•´ ë“œë¦½ë‹ˆë‹¤.", list(questions.keys()))

    # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ì˜ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
    for question in questions[selected_category]:
        with st.expander(question):
            # ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ ë‹µë³€ ìƒì„±
            if st.button(f"Get AI-generated answers", key=f"button_{question}"):
                with st.spinner(f"Generating answers with AI..."):
                    answer = get_answer(question)
                st.session_state[f"{question}"] = f"**Answer:** {answer}"

            # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë‹µë³€ í‘œì‹œ
            if f"{question}" in st.session_state:
                st.write(st.session_state[f"{question}"])
    
    # ì§ì ‘ ì§ˆë¬¸ ì…ë ¥       
    st.divider()
    st.subheader("ì›í•˜ëŠ” ë©´ì ‘ ì§ˆë¬¸ì´ ì—†ìœ¼ì‹ ê°€ìš”? ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹œë©´ AIê°€ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    custom_question = st.text_input("ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
    if st.button("ë‹µë³€ ìƒì„±í•˜ê¸°"):
        with st.spinner("Generating answers with AI..."):
            answer = get_answer(custom_question)
        st.write(f"**Answer:** {answer}")
                
if __name__ == "__main__":
    show()