import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate

class InterviewAssistant:
    def __init__(self):
        self.question_categories = {
            "ê¸ˆìœµ ë° ê²½ì œ": [
                "ESG ê¸ˆìœµì˜ í™œì„±í™” ë°©ì•ˆ",
                "ì‚°ì—…êµ¬ì¡° ê³ ë„í™”ë¥¼ ìœ„í•œ íˆ¬ìì „ëµ",
                "í¬ìŠ¤íŠ¸ ì½”ë¡œë‚˜ ì‹œëŒ€ì˜ ê¸°ì—…êµ¬ì¡°ì¡°ì • ë°©ì•ˆ",
                "ì¤‘ì†Œê¸°ì—… ê¸ˆìœµì§€ì› í™•ëŒ€ ì „ëµ",
                "ë°˜ë„ì²´ ì‚°ì—… ê²½ìŸë ¥ ë¶„ì„ê³¼ ê¸ˆìœµ ì§€ì› ë°©ì•ˆ",
                "ê¸°ì—… ì‹ ìš©í‰ê°€ ëª¨ë¸ ê°œì„  ë°©ì•ˆ",
                "ì‹ ì¬ìƒì—ë„ˆì§€ ì‚°ì—… íˆ¬ìì „ëµ",
                "ìµœê·¼ ê¸€ë¡œë²Œ ê¸ˆìœµì‹œì¥ ì´ìŠˆëŠ”?",
                "ì‚°ì—…ì€í–‰ì˜ ì •ì±…ê¸ˆìœµ ì—­í• ì€?",
                "ë””ì§€í„¸ ê¸ˆìœµì˜ ë°œì „ ë°©í–¥",
            ],
            "ê¸°ì—… ë° ì •ì±…": [
                "êµ¬ì¡°ì¡°ì • ëŒ€ìƒ ê¸°ì—… ì‹¤ì‚¬ ë°©ì•ˆ",
                "ê¸°ì—…ê°€ì¹˜ í‰ê°€ ë°©ë²•ë¡  ì„¤ëª…",
                "ì°½ì—…ì´ë¼ëŠ” íŠ¹ì´í•œ ì´ë ¥ì„ ê°–ê³  ìˆëŠ”ë°, ë³¸ì¸ì´ ë‹´ë‹¹í–ˆë˜ í¬ì§€ì…˜ì€ ë¬´ì—‡ì¸ì§€?",
                "ë²¤ì²˜ê¸°ì—… ì§€ì›ì— ê´€ì‹¬ì´ ìˆë‹¤ê³  í–ˆëŠ”ë°, ì •ì±…ê¸ˆìœµì„ í†µí•´ íˆ¬ì ë° ì§€ì›ì´ ë°˜ë“œì‹œ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë¶„ì•¼ëŠ” ì–´ë””ì¸ê°€?",
                "ITë¶„ì•¼ë“  3ì°¨ ì„œë¹„ìŠ¤ ë¶„ì•¼ë“  ì¼ë‹¨ ìˆ˜ìµì´ ë°œìƒí•˜ëŠ” ë¶„ì•¼ë¶€í„° ì§€ì›í•´ì•¼ í•œë‹¤ëŠ” ì˜ê²¬ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ì§€?",
                "ì‚°ì–¸ì€í–‰ ëª¨ë°”ì¼ ë±…í‚¹ê³¼ ë‹¤ë¥¸ ì€í–‰ì˜ ëª¨ë°”ì¼ ë±…í‚¹ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                "í•œêµ­ì‚°ì—…ì€í–‰ì— ê´€ë ¨í•œ ìµœê·¼ ì´ìŠˆë¥¼ ë§í•´ë³´ì„¸ìš”",
                "ì‚°ì—…ì€í–‰ë‹´ë‹¹ìë¼ë©´ ì–´ë–¤ ê¸°ì—…ì˜ M&Aë¥¼ ì£¼ì„ í•˜ê² ëŠ”ê°€?",
                "ê¸°ì—…ì˜ ì¡´ì¬ ì´ìœ ëŠ” ë­ë¼ê³  ìƒê°í•©ë‹ˆê¹Œ?",
            ],
            "ê°œì¸ ë° ê²½í—˜": [
                "30ì´ˆ ìê¸°ì†Œê°œ",
                "ê³µëª¨ì „ í™œë™ì´ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í™œë™ì¸ì§€? ê°ˆë“± ê²½í—˜ì´ ìˆì—ˆëŠ”ì§€?",
                "ê¸°ì¡´ ë¶ˆí¸ì‚¬í•­ì„ ì´ë ‡ê²Œ ë°”ê¿”ë´¤ë‹¤!í•˜ëŠ” ê²½í—˜?",
                "ì¡°ì§ì— ë“¤ì–´ì™”ì„ ë•Œ ì–´ë–¤ ë¶„ìœ„ê¸°ë¥¼ ì œì¼ í˜ë“¤ì–´í•˜ëŠ”ê°€? ê·¸ ì–´ë ¤ì›€ì„ ì–´ë–»ê²Œ í•´ê²°í•´ ë‚˜ê°ˆ ê²ƒì¸ê°€?",
                "ë‚˜ì˜ ê°•ì  í•œê°€ì§€ í˜¹ì€ íƒ€ì¸ìœ¼ë¡œë¶€í„° ë“¤ì—ˆë˜ ë§",
                "ìì‹ ì´ ë¦¬ë”ë¼ê³  ìƒê°í•©ë‹ˆê¹Œ, íŒ”ë¡œì›Œë¼ê³  ìƒê°í•©ë‹ˆê¹Œ?",
                "ì‘ë…„ì—ë„ ìš°ë¦¬ íšŒì‚¬ì— ì§€ì›í–ˆëŠ”ë°, ë©´ì ‘ì—ì„œ ì™œ íƒˆë½í•œ ê²ƒ ê°™ë‚˜ìš”?",
                "ì‚°ì—…ì€í–‰ê³¼ ê¸°íƒ€ ê³µê¸°ì—…ì˜ ì°¨ì´ì ì€?",
                "ìì‹ ì˜ ê°€ì¥ í° ì¥ì ì´ ë¬´ì—‡ì¸ê°€?",
            ],
            "ì‚¬íšŒ ë° ê¸°íƒ€": [
                "ì†Œë“ ë¶ˆí‰ë“±",
                "ì´ˆë“±í•™êµì—ì„œ ì¸ì„±êµìœ¡ì„ ì‹œí‚¤ëŠ” ê²ƒì— ëŒ€í•´ ì°¬ë°˜ í† ë¡ ì„ í•˜ë¼",
                "ë¯¸êµ­ ì •ì¹˜ ìº í˜ì¸ì´ í•œêµ­ê³¼ ì–´ë–¤ ì ì—ì„œ ë‹¤ë¥´ë‹¤ê³  ìƒê°í•˜ëŠ”ê°€?",
                "ë³¸ì¸ì´ ìƒê°í•˜ëŠ” ì„±ê³µì´ë€ ë¬´ì—‡ì¸ê°€?",
                "ì •ì˜ë€ ë¬´ì—‡ì´ë¼ ìƒê°í•˜ëŠ”ê°€?",
                "êµ­ë¯¼ì—°ê¸ˆì œë„ì— ê´€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ëŠ”ê°€?",
                "ê·€í™”í•œ ì„ ìˆ˜ê°€ ì˜¬ë¦¼í”½ ì¶œì „ì„ í†µí•´ ê¸ˆë©”ë‹¬ íšë“í•˜ëŠ” ê²ƒì— ëŒ€í•œ ì˜ê²¬",
                "ì‚¬ê´€í•™êµ ê·œì œì— ê´€í•œ ë³¸ì¸ì˜ ìƒê°",
                "í•˜ìš°ìŠ¤í‘¸ì–´ ì§€ì›ì— ëŒ€í•œ ì°¬ë°˜",
            ],
        }

    def generate_answer(self, question):
        """Generates an answer for the given question using LangChain's OpenAI integration."""
        try:
            # Initialize the OpenAI model via LangChain
            llm = ChatOpenAI(model="gpt-4", temperature=0.7)
            
            # Create a prompt template
            prompt = ChatPromptTemplate.from_messages([
                ("system", "ì‚°ì—…ì€í–‰ ë©´ì ‘ ì¤€ë¹„ë¥¼ ë„ì™€ì£¼ëŠ” AIì…ë‹ˆë‹¤."),
                ("user", f"ì§ˆë¬¸: {question}. ì´ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„¸íˆ ì‘ì„±í•´ì£¼ì„¸ìš”.")
            ])

            # Generate the response
            response = llm.invoke(prompt.format_messages())

            return response['text'].strip()
        except Exception as e:
            return f"ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def display_ui(self):
        """Displays the Streamlit user interface."""
        if "selected_category" not in st.session_state:
            st.session_state.selected_category = None

        st.title("ğŸ’¼ì‚°ì—…ì€í–‰ ë©´ì ‘ ì¤€ë¹„ ë„ìš°ë¯¸")
        st.write("ë©´ì ‘ ì§ˆë¬¸ì„ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ë©´ GPT-4ê°€ ë‹µë³€ì„ ìƒì„±í•´ ë“œë¦½ë‹ˆë‹¤.")
        st.write("---")

        # Display category buttons
        st.write("### ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        cols = st.columns(len(self.question_categories))
        for i, category in enumerate(self.question_categories.keys()):
            if cols[i].button(category):
                st.session_state.selected_category = category

        st.write("---")

        # Display questions based on selected category
        if st.session_state.selected_category:
            selected_category = st.session_state.selected_category
            st.write(f"**ì„ íƒí•œ ì¹´í…Œê³ ë¦¬: {selected_category}**")
            selected_question = st.selectbox(
                "ì§ˆë¬¸ì„ ì„ íƒí•˜ì„¸ìš”:", self.question_categories[selected_category]
            )

            # Input for custom questions
            custom_question = st.text_input("ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒ ì‚¬í•­):")

            # Generate answer button
            if st.button("ë‹µë³€ ìƒì„±í•˜ê¸°"):
                question = custom_question.strip() if custom_question else selected_question
                if not question:
                    st.warning("ì§ˆë¬¸ì„ ì„ íƒí•˜ê±°ë‚˜ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    return

                st.info(f"ì§ˆë¬¸: {question}")
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    answer = self.generate_answer(question)
                st.success("ë‹µë³€ ìƒì„± ì™„ë£Œ!")
                st.write(answer)

# ì‹¤í–‰
if __name__ == "__main__":
    assistant = InterviewAssistant()
    assistant.display_ui()
